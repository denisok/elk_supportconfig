# common logstash pipeline for supportconfig

input {
	file {
	 	path => "/tmp/supportconfig/**/*.txt"
		start_position => "beginning"
		type => supportconfig
		discover_interval => 1
		sincedb_path => "/dev/null"

		add_field => { "sp_type" => "general" }

		# add file/path here if there is a separate conf file for it
		# or those that shouldn't be uploaded
		exclude => [ 
				"messages*.txt", 
				"hardware.txt", 
				"open-files.txt",
				"proc.txt",
				"warn*.txt",
				"y2log.txt",
				"udev.txt",
				"sysfs.txt",
				"network.txt",
				"boot.txt",
				"memory.txt",
				"modiles.txt",
				"mpio.txt",
				"plugin-ses.txt",
				"rpm.txt",
				"updates*.txt"
			]

		codec => multiline {
        		pattern => "^#=="
        		negate => true
        		what => "previous"
			auto_flush_interval => 5
		}                         
	}
}

filter {
	grok { 
		match => { "path" => "nts(_SR%{NUMBER:sr}_|_)(?<sp_host>[^_]*)_%{NUMBER:date}_%{NUMBER:time}(?:_%{UUID:sp_uid}|)%{GREEDYDATA:file_path}" }
	}

	if [type] == "supportconfig" {
		if [sp_type] == "general" {
			grok {
				match => { "message" => "(?m)^#==\[\s(?<entry_type>.*?(?=\s]))\s]=+#\n?#?\s?(?<entry_val>[^\n]*)\n?(?<entry_out>^.*)" }
			}
		}
		mutate { 
			update => { "host" => "%{sp_host}" }
			update => { "date" => "%{date}%{time}" }
		}
		date { 
			match => [ "date", "yyMMddHHmm" ]
			target => "@date"
		}
	}
}

output {
	if [@metadata][type] == "kibana" { 
		#stdout { codec => rubydebug { metadata => true } }

		elasticsearch { 
			hosts => "elasticsearch:9200"
			index => ".kibana"
			document_type => "%{[@metadata][_type]}"
			document_id => "%{[@metadata][_id]}"
			user => "elastic"
			password => "changeme"
		}

	} else { 
		#stdout { codec => rubydebug }

		elasticsearch { 
			hosts => "elasticsearch:9200"
			document_type => "%{type}"
			index => "%{type}-%{host}"
			user => "elastic"
			password => "changeme"
		}

	}
}
